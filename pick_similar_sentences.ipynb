{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "with open('w2i_movie_names.json') as f:\n",
    "    w2i_movies = json.load(f)\n",
    "\n",
    "with open('i2w_movie_names.json') as f:\n",
    "    i2w_movies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('movie_data_separate.pkl', 'rb') as f:\n",
    "    movie_data = pickle.load(f)\n",
    "    \n",
    "with open('neighbours.pkl', 'rb') as f:\n",
    "    neighbours = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('w2i_review_comments_fact.json') as f:\n",
    "        w2i_rpc = json.load(f)\n",
    "with open('i2w_review_comments_fact.json') as f:\n",
    "        i2w_rpc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20155"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i2w_rpc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i_rpc['unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(k, embeddings):\n",
    "    k += 1\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='kd_tree')\n",
    "    nbrs.fit(embeddings)\n",
    "    distances, indices = nbrs.kneighbors(embeddings)\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_utterance_embedding(utterance, embed_dim, stopwords, w2i, trained_word_embeddings):\n",
    "    #obtain the average embedding for the whole utterance using the word embeddings\n",
    "    #learned in the movie embedding training\n",
    "    utterance_embedding = torch.zeros(embed_dim)\n",
    "    \n",
    "    count = 0\n",
    "    for w in utterance:\n",
    "        #skip stop words\n",
    "        if w in stop_words or w in ['<SOS>', '<EOS>']:\n",
    "            pass\n",
    "        elif w in w2i: #word in dictionary\n",
    "            #print('word',w)\n",
    "            word_em = trained_word_embeddings[w2i[w]]\n",
    "            utterance_embedding += word_em\n",
    "            count += 1\n",
    "        else:\n",
    "            word_em = trained_word_embeddings[w2i_rpc['unknown']] #unk\n",
    "            utterance_embedding += word_em\n",
    "            count += 1\n",
    "            \n",
    "    #print(utterance_embedding, utterance_embedding/count, count)\n",
    "    avg_utterances_embedding = utterance_embedding/count\n",
    "    \n",
    "    return avg_utterances_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt0061452\n",
      "[[ 0  6 42 26 30 35]\n",
      " [37  1 32 16  2 21]\n",
      " [ 2 34 39 28 43 40]\n",
      " [ 3 46 45 40  4 39]\n",
      " [ 4 45 43 36 34 44]\n",
      " [ 5 43 45 35 40 44]\n",
      " [ 0  6 42 26 30 35]\n",
      " [ 7 20 36 45 12 34]\n",
      " [ 8 35 40 44 45 43]\n",
      " [ 9 34 44 45 40 11]\n",
      " [10 21 29 28 22 45]\n",
      " [11 34 45 46 40  4]\n",
      " [12 45  4 36 34 46]\n",
      " [13 34 11 40 45 46]\n",
      " [14 30 43 28 45 40]\n",
      " [15 31 40 44 34 43]\n",
      " [16 32  1 37  3 39]\n",
      " [17 40 31 44 15 43]\n",
      " [18 45 39 43  8 44]\n",
      " [19 43 28 40 44 39]\n",
      " [20 45 36 35  4 34]\n",
      " [21 10 28 22 39 29]\n",
      " [22 40 35 28 44 45]\n",
      " [23 45 40 46 39 44]\n",
      " [24 45 39 43 34 40]\n",
      " [25 40 30 44 43 45]\n",
      " [ 0  6 42 26 30 35]\n",
      " [27 43 40 45 28  4]\n",
      " [28 40 22 43 45 29]\n",
      " [29 45 40 30 43 34]\n",
      " [30 40 45 35 44 43]\n",
      " [31 15 40 44 43 39]\n",
      " [32 37  1 16 28  3]\n",
      " [33 22 40 45 43 28]\n",
      " [34 11 40 45 43 35]\n",
      " [35 45 43 34 40  8]\n",
      " [36  4 45 34 43 20]\n",
      " [37  1 32 16  2 21]\n",
      " [38 30 40 22  8 34]\n",
      " [39 44 45 40 34 35]\n",
      " [40 43 45 44 34 28]\n",
      " [41 44 34 45 39  4]\n",
      " [ 0  6 42 26 30 35]\n",
      " [43 45 40  4 35 34]\n",
      " [44 45 39 40 43 34]\n",
      " [45 43  4 44 40 35]\n",
      " [46  3 45 11 40 34]]\n",
      "-1 -1\n",
      "1 0\n",
      "which is your favourite character in this\n",
      "my favorite character was peter sellers version of james bond he along with woody allen gave the funniest performances in the film\n",
      "8 0\n",
      "which is your favourite character in this\n",
      "my favorite character was bond because he is always dynamic\n",
      "5 0\n",
      "which is your favourite character in this\n",
      "my favorite character was peter sellers version of james bond he along with woody allen gave the funniest performances in the film\n",
      "5 4\n",
      "yeah that was brilliant some of the scenes seem so real i feel i was present right there at that very moment\n",
      "its my favorite aside from goldeneye that first chase is the best action sequence in history im still blow away by it\n",
      "6 3\n",
      "casino royale seems to be little more than an excuse to have a multimillion dollar party at the studios expense\n",
      "casino royale also has probably the best of bonds wit: everyone is going to know that you died scratching my balls\n"
     ]
    }
   ],
   "source": [
    "def get_similar_movie_responses(movie_id, n, model, w2i, i2w, utterance, neighbours, stop_words):\n",
    "    '''\n",
    "    w2i and i2w are vocabularies for plot-review-comments\n",
    "    utterance is a tokenized sentence of strings\n",
    "    returning a list of tokenized sentences of strings\n",
    "    '''\n",
    "    similar_movie_data = neighbours[movie_id] \n",
    "    similar_movie_id = similar_movie_data.imdb_id\n",
    "    print(similar_movie_id)\n",
    "    similar_movie_chat = similar_movie_data.chat\n",
    "    \n",
    "    trained_word_embeddings = model['model_state_dict']['word_embedding.weight']\n",
    "    #print(trained_word_embeddings.shape)\n",
    "    embed_dim = trained_word_embeddings.shape[1]\n",
    "    \n",
    "    avg_utterance_embedding = get_average_utterance_embedding(utterance, embed_dim, stop_words, w2i, trained_word_embeddings)\n",
    "    \n",
    "    similar_responses = []  \n",
    "    \n",
    "    all_chat_reps = []    \n",
    "    all_chat_reps.append(avg_utterance_embedding.numpy())\n",
    "    all_chat_indices = [(-1,-1)]\n",
    "    for c in range(len(similar_movie_chat)):\n",
    "        chat = similar_movie_chat[c]\n",
    "        enc = chat.encoder_chat\n",
    "        dec = chat.decoder_chat\n",
    "        \n",
    "        for s in range(len(enc)):\n",
    "            sent = enc[s]            \n",
    "            sent = tknzr.tokenize(sent)\n",
    "            #print(sent)\n",
    "            sent_avg_embedding = get_average_utterance_embedding(sent, embed_dim, stop_words, w2i, trained_word_embeddings)\n",
    "            \n",
    "            all_chat_reps.append(sent_avg_embedding.numpy())\n",
    "            #chat index and then sentence index for speaker 1\n",
    "            #so that we can get the related speaker 2 utterance\n",
    "            all_chat_indices.append((c,s))  \n",
    "        \n",
    "    #print(all_chat_reps[0])\n",
    "    distances, indices = k_nearest_neighbors(n, all_chat_reps)\n",
    "    print(indices)\n",
    "    neighbours = indices[0]\n",
    "    \n",
    "    for n in neighbours:\n",
    "        (c,s) = all_chat_indices[n]\n",
    "        print(c,s)\n",
    "        if c != -1:\n",
    "            print(similar_movie_chat[c].encoder_chat[s])\n",
    "            print(similar_movie_chat[c].decoder_chat[s])\n",
    "            similar_responses.append(tknzr.tokenize(similar_movie_chat[c].decoder_chat[s]))\n",
    "            \n",
    "    return similar_responses\n",
    "\n",
    "movie_id = 'tt0058150'\n",
    "n = 5\n",
    "utterance = ['which', 'is', 'your', 'favourite', 'character'] #speaker 1 utterance\n",
    "model = torch.load('model_movie.pkl', map_location='cpu' )\n",
    "similar_responses = get_similar_movie_responses(movie_id, n, model, w2i_rpc, i2w_rpc, utterance, neighbours,stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['my',\n",
       "  'favorite',\n",
       "  'character',\n",
       "  'was',\n",
       "  'peter',\n",
       "  'sellers',\n",
       "  'version',\n",
       "  'of',\n",
       "  'james',\n",
       "  'bond',\n",
       "  'he',\n",
       "  'along',\n",
       "  'with',\n",
       "  'woody',\n",
       "  'allen',\n",
       "  'gave',\n",
       "  'the',\n",
       "  'funniest',\n",
       "  'performances',\n",
       "  'in',\n",
       "  'the',\n",
       "  'film'],\n",
       " ['my',\n",
       "  'favorite',\n",
       "  'character',\n",
       "  'was',\n",
       "  'bond',\n",
       "  'because',\n",
       "  'he',\n",
       "  'is',\n",
       "  'always',\n",
       "  'dynamic'],\n",
       " ['my',\n",
       "  'favorite',\n",
       "  'character',\n",
       "  'was',\n",
       "  'peter',\n",
       "  'sellers',\n",
       "  'version',\n",
       "  'of',\n",
       "  'james',\n",
       "  'bond',\n",
       "  'he',\n",
       "  'along',\n",
       "  'with',\n",
       "  'woody',\n",
       "  'allen',\n",
       "  'gave',\n",
       "  'the',\n",
       "  'funniest',\n",
       "  'performances',\n",
       "  'in',\n",
       "  'the',\n",
       "  'film'],\n",
       " ['its',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'aside',\n",
       "  'from',\n",
       "  'goldeneye',\n",
       "  'that',\n",
       "  'first',\n",
       "  'chase',\n",
       "  'is',\n",
       "  'the',\n",
       "  'best',\n",
       "  'action',\n",
       "  'sequence',\n",
       "  'in',\n",
       "  'history',\n",
       "  'im',\n",
       "  'still',\n",
       "  'blow',\n",
       "  'away',\n",
       "  'by',\n",
       "  'it'],\n",
       " ['casino',\n",
       "  'royale',\n",
       "  'also',\n",
       "  'has',\n",
       "  'probably',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'bonds',\n",
       "  'wit',\n",
       "  ':',\n",
       "  'everyone',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'know',\n",
       "  'that',\n",
       "  'you',\n",
       "  'died',\n",
       "  'scratching',\n",
       "  'my',\n",
       "  'balls']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
